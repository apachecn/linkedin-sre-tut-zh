# 基础设施服务

> 原文:[https://LinkedIn . github . io/school-of-sre/level 102/networking/infra structure-features/](https://linkedin.github.io/school-of-sre/level102/networking/infrastructure-features/)

> *需要考虑的一些方面是，底层数据中心基础设施是否支持 ToR 弹性，即链路捆绑(绑定)、BGP、选播服务支持、负载平衡器、防火墙、服务质量等功能。*

如前所述，要大规模部署应用程序，需要基础设施支持某些功能。本节将介绍不同的可用选项及其适用性。

### ToR 连接

这是最常见的故障点之一(考虑到部署的规模)，有不同的选项可以将服务器连接到 ToR。我们将在下面详细介绍它们，

#### 一个

这是所有选项中最简单的。其中服务器的网卡连接到一个 ToR。这种方法的优点是，使用的交换机端口数量最少，允许 DC 结构支持服务器基础架构的快速增长(注意:不仅 ToR 端口得到有效利用，DC 结构中的上层交换层也是如此，端口使用效率也很高)。不利的一面是，如果 ToR、链接或 NIC 出现问题，服务器可能无法访问。这将对有状态应用程序产生更大的影响，因为现有的连接会突然断开。

![Graphical user interface, application Description automatically
generated with medium
confidence](../Images/e113f5105e7944c145d7e7e12384ee01.png)

图 4:单 ToR 设计

#### 双重 ToR

在此选项中，每台服务器都连接到同一机柜的两个 ToR。这可以设置为主动/被动模式，从而在 ToR/链路/NIC 故障期间提供弹性。弹性可以在第 2 层或第 3 层实现。

##### 第二层

在这种情况下，两个链路在服务器端作为[绑定](https://en.wikipedia.org/wiki/Link_aggregation)捆绑在一起(其中一个 NIC 扮演主动角色，另一个扮演被动角色)。在交换机端，这两个链路构成了[多机箱延迟](https://en.wikipedia.org/wiki/Multi-chassis_link_aggregation_group)的一部分(类似于绑定，但分布在交换机上)。这里的先决条件是，两个 ToR 都应该是同一个第 2 层域的一部分。IP 地址配置在服务器的绑定接口和交换机端的 SVI 上。

![Diagram Description automatically
generated](../Images/87d66ba076ca33f8b7242f616a083a13.png)

注意:在这种情况下，ToR 2 的作用只是提供弹性。

图 5:双 ToR 第 2 层设置

##### 第三层

在这种情况下，两条链路都被配置为独立的第 3 层接口。弹性是通过建立路由协议(如 BGP)来实现的。其中一个链接被给予比另一个更高的优先级。在这种情况下，两个 ToR 可以在第 3 层模式下独立设置。服务器需要一个虚拟地址，服务必须绑定到这个虚拟地址。

![Diagram Description automatically
generated](../Images/f6bcf0872f997b7902aea4743e8db3e7.png)

注意:在这种情况下，ToR 2 的作用只是提供弹性。

图 6:双 ToR 第 3 层设置

虽然双 ToR 的弹性更好，但缺点是使用的端口数量。随着 ToR 中的接入端口加倍，主干层中所需的端口数量也加倍，并不断级联到更高层。

| 类型 | 一个 | 双 ToR(第 2 层) | 双 ToR(第 3 层) |
| --- | --- | --- | --- |
| 弹性 <sup>1</sup> | 否 <sup>2</sup> | 是 | 是 |
| 端口使用 | 1:1 | 1:2 | 1:2 |
| 布线 | 较少的 | 更大的 | 更大的 |
| DC 织物的成本 | 低的 | 高的 | 高的 |
| 所需的 ToR 功能 | 低的 | 高的 | 中等 |

<sup>1</sup>ToR/Link/NIC 方面的弹性

<sup>2</sup> 作为替代方案，弹性可以在应用层解决。

除了上面提到的那些，一个应用程序可能需要基础设施之外的更多功能来大规模部署。有些是，

### 任播

如前一节所述，在大规模部署中，任播是一种将服务分布在不同机柜中，同时仍有流量流向每台服务器的方法。要做到这一点，需要做两件事

1.  ToR 和服务器之间的路由协议(宣布任播地址)

2.  支持基础架构中的 ECMP(等价多路径)负载平衡，以在机柜间分配流量。

### 负载平衡

与任播类似，另一种实现跨服务器负载平衡的方法(托管特定的应用程序)是使用负载平衡器。这些可以用不同的方式实现

1.  硬件负载平衡器:LB 设备放置在通信流的内联中，并查看传入数据包中的第 3 层和第 4 层信息。然后确定连接将被重定向到的真实主机集。如 [Scale](https://linkedin.github.io/school-of-sre/level102/networking/scale/#load-balancer) 主题所述，这些负载平衡器可以通过两种方式进行设置，

    *   单臂模式:在这种模式下，负载平衡器只处理传入 VIP 的请求。来自服务器的响应直接发送到客户端。有两种方法可以实现这一点，

        *   L2·DSR:负载均衡器和真正的服务器在同一个 VLAN。在收到一个传入的请求时，负载均衡器会识别真正的服务器来重定向该请求，然后修改该以太网帧的目的 mac 地址。在处理这个包时，真正的服务器直接响应客户机。

        *   [L3 DSR](https://github.com/yahoo/l3dsr) :在这种情况下，负载平衡器和真实服务器不需要在同一个 VLAN 中(消除第 2 层的复杂性，如运行 STP、管理更广泛的广播域等)。在收到请求时，负载平衡器通过修改数据包的目的 IP 地址重定向到真实服务器。与此同时，数据包的 DSCP 值被设置为预定义的值(为该 VIP 映射)。收到此数据包后，实际服务器使用 DSCP 值来确定回送地址(VIP 地址)。响应再次直接到达客户端。

    *   双臂模式:在这种情况下，负载均衡器会处理传入和传出的流量。

2.  基于 DNS 的负载均衡器:在这里，DNS 服务器检查真实服务器的健康状况，并以这样的方式解析域，使得客户端可以连接到集群中的不同服务器。该部分在[规模](https://linkedin.github.io/school-of-sre/level102/networking/scale/#dns-based-load-balancing)的部署章节中有详细解释。

3.  基于 IPVS 的负载平衡:这是另一种方法，IPVS 服务器将自己作为服务端点呈现给客户端。收到请求后，IPVS 会将请求定向到真实的服务器。可以设置 IPVS 为真正的服务器运行状况。

### 精灵

需要连接到互联网上的目的地，但不想暴露其配置的 NIC 地址的主机将需要网络地址转换(NAT)。在这种情况下，防火墙会将(内部服务器的)地址转换为公共地址。代理服务器、邮件服务器等就是很好的例子。

### 服务质量

服务质量是一种为少数数据包提供区别对待的手段。这些可以在转发队列或带宽预留中提供优先级。在数据中心场景中，根据带宽预订比率，对 QoS 的需求会有所不同，

1.  1:1 的带宽订阅比率:在这种情况下，服务器到 ToR 的连接(该机柜中的所有服务器)带宽应等于 ToR 到主干交换机的连接。对于上层也是类似的。在这种设计中，链路上不会发生拥塞，因为总会有足够的带宽可用。在这种情况下，QoS 能够带来的唯一区别是，它为转发队列中的某些数据包提供优先处理。注意:当数据包在不同速度(如 100Gbps、10Gbps)的端口之间移动时，会发生数据包缓冲。

2.  超额预订网络:在这种情况下，并非所有层都保持带宽预订比率，例如，与 ToR 与服务器带宽相比，ToR 上行链路的带宽可能较低(这有时称为超额预订比率)。在这种情况下，有可能出现拥堵。这里可能需要 QoS，以便为某些类型的业务流提供优先级和带宽预留。